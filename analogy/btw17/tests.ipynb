{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import w2vAida\n",
    "import analogy_completion\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CONFIG\n",
    "model_version = \"w2v\"   # one of s2v, aida, or w2v\n",
    "run_completion_experiment = False\n",
    "run_ranking_experiment = True\n",
    "exclude_minority_vectores = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## logging\n",
    "log_path = \"/opt3/home/lofi/github/SimilarityAndAnalogy/analogy/btw17/log/\"\n",
    "log_filename = model_version+\"_\"+(\"NoMinority\" if exclude_minority_vectores else \"Minority\")+\".log\"\n",
    "\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import sys\n",
    "\n",
    "log = logging.getLogger('')\n",
    "log.setLevel(logging.DEBUG)\n",
    "format = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "#ch = logging.StreamHandler(sys.stdout)\n",
    "#ch.setFormatter(format)\n",
    "#log.addHandler(ch)\n",
    "\n",
    "#fh = logging.handlers.RotatingFileHandler(log_path+log_filename, maxBytes=(1048576*5), backupCount=7)\n",
    "fh = logging.FileHandler(log_path+log_filename, mode=\"w\")\n",
    "fh.setFormatter(format)\n",
    "\n",
    "log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### VERSION on IS69\n",
    "if (model_version == \"s2v\"):\n",
    "    model_file = \"/opt3/home/pratima/thesis_final/models/s2v.model.bin\"\n",
    "    vocab_file = \"/opt3/home/lofi/word2vec_models/s2v.vocab\"\n",
    "    delimeter = \"|\"\n",
    "elif (model_version == \"aida\"):\n",
    "    model_file = \"/opt3/home/pratima/thesis_final/models/aida.model.bin\"\n",
    "    vocab_file = \"/opt3/home/lofi/word2vec_models/aida.vocab\"\n",
    "    delimeter = \":\"\n",
    "logging.debug(\"version: \"+model_version)\n",
    "golddata_file = \"/opt3/home/lofi/github/SimilarityAndAnalogy/analogy/testData/AGS/AGS-V02.txt\"\n",
    "output_file = \"/opt3/home/lofi/github/SimilarityAndAnalogy/analogy/testData/AGS/results//test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LOCAL VERSION\n",
    "\n",
    "#model_file = \"D:/data/analogy/pratima_w2v_models/aida.model.bin\"\n",
    "#model_file = \"D:/data/analogy/pratima_w2v_models/s2v.model.bin\"\n",
    "#vocab_file = \"D:/data/analogy/pratima_w2v_models/aida.vocab\"\n",
    "#golddata_file = \"../testData/AGS/AGS-V02.txt\"\n",
    "#output_file = \"./result/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LOAD AGS\n",
    "\n",
    "def loadGoldData(dataset):\n",
    "    with open(dataset, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        simGold = []\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            line = lines[i].strip()\n",
    "            i += 1\n",
    "            if line.startswith(\":\"):\n",
    "                continue\n",
    "            if line.startswith(\"\\n\"):\n",
    "                i += 1\n",
    "                continue\n",
    "            splits = line.split(\" \")\n",
    "            correctedsplits = [ ]\n",
    "            correctedsplits.append(splits[0])\n",
    "            correctedsplits.append(splits[1])\n",
    "            correctedsplits.append(splits[2])\n",
    "            correctedsplits.append(splits[3])\n",
    "            correctedsplits.append(splits[4])\n",
    "            correctedsplits.append(splits[5])\n",
    "            correctedsplits.append(splits[6])\n",
    "            correctedsplits.append(splits[7])\n",
    "            #correctedsplits.append(splits[8])\n",
    "            simGold.append(correctedsplits)\n",
    "            #print(correctedsplits)\n",
    "        return simGold\n",
    "    \n",
    "analogydataset = loadGoldData(golddata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load local with delimeter |\n"
     ]
    }
   ],
   "source": [
    "### Load Training Model. Note: s2v needs | delimeter, \n",
    "model=w2vAida.Word2Vec.load_word2vec_format(fname=model_file, binary=True, fvocab=vocab_file, delimeter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# just a test \n",
    "if (model_version==\"s2v\"):\n",
    "    print(model.n_similarity(['sushi|noun', 'shop|noun'], ['japanese|noun', 'restaurant|noun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### completion query!\n",
    "if run_completion_experiment:\n",
    "    for value in analogydataset:\n",
    "        temp = model.most_similar_new(positive=[value[2], value[1]], negative=[value[0]],topn=1)\n",
    "        for values in temp:\n",
    "            if ':' in values[0]:\n",
    "                v = values[0]\n",
    "                v1 = v.split(':')\n",
    "                similarityvalue=v1[0]\n",
    "            else:\n",
    "                similarityvalue=values[0]\n",
    "        print(\"{}:{} :: {}:{}  >> {}\".format(value[0], value[1], value[2], value[3], similarityvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_columns=('a1','a2','b1','b2','ags_rating','model_rating')\n",
    "result = pd.DataFrame(columns=r_columns)\n",
    "result_file_name=log_path+model_version+\"_\"+(\"NoMinority\" if exclude_minority_vectores else \"Minority\")+\".result.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tired:sleep :: thirsty:drink  >> 0.8244511215034911    reference rating 5\n",
      "tired:sleep :: sad:cry  >> 0.7215932798480629    reference rating 4.7\n",
      "tired:sleep :: hungry:eat  >> 0.767812951596686    reference rating 4.6\n",
      "tired:sleep :: fresh:work  >> 0.6284949519846539    reference rating 3.6\n",
      "tired:sleep :: lazy:couch  >> 0.7497785577716891    reference rating 3\n",
      "tired:sleep :: bored:read  >> 0.7080494526116101    reference rating 2.6\n",
      "tired:sleep :: happy:sit  >> 0.7837585912811622    reference rating 1.2\n",
      "lifejacket:boat :: belt:car  >> 0.8479072867781147    reference rating 5\n",
      "lifejacket:boat :: seatbelt:airplane  >> 0.6844971447127233    reference rating 5\n",
      "lifejacket:boat :: airbag:car  >> 0.8388618580291823    reference rating 4.6\n"
     ]
    }
   ],
   "source": [
    "### RANKING EXPERIMENT\n",
    "if run_ranking_experiment:\n",
    "\n",
    "    \n",
    "    duplicatecount=0\n",
    "    count=0\n",
    "    countlines=0\n",
    "    previouscheckvalue=0\n",
    "    total=0\n",
    "    nextval = 0\n",
    "\n",
    "    for value in analogydataset:\n",
    "        #if(value[6]==word):\n",
    "        r_similarity = model.n_similarity_new([value[0], value[1]],[value[2],value[3]])\n",
    "        print(\"{}:{} :: {}:{}  >> {}    reference rating {}\".format(value[0], value[1], \n",
    "                                                                    value[2], value[3], r_similarity, value[4]))\n",
    "\n",
    "        countlines+=1\n",
    "        originalRating=value[4]\n",
    "        originalcheckvalue=value[0]\n",
    "       \n",
    "        row = pd.DataFrame([[value[0],value[1],value[2],value[3],value[4],r_similarity]],columns=r_columns)\n",
    "        result=result.append(row)\n",
    "        result.to_csv(result_file_name, encoding='utf-8')\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model.vocab[\"apple|ent\"].count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(model.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
