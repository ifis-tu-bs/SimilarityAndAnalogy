{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import w2vAida\n",
    "import analogy_completion\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CONFIG\n",
    "model_version = \"s2v\"   # one of s2v, aida, or w2v\n",
    "gold_set = \"SAT\" # one of SAT, AGS\n",
    "run_completion_experiment = False\n",
    "run_ranking_experiment = True\n",
    "exclude_minority_vectores = False\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## logging\n",
    "log_path = \"/opt3/home/lofi/github/SimilarityAndAnalogy/analogy/btw17/log/\"\n",
    "log_filename = model_version+\"_\"+gold_set+\"_\"+(\"NoMinority\" if exclude_minority_vectores else \"Minority\")+\".log\"\n",
    "\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import sys\n",
    "\n",
    "log = logging.getLogger('')\n",
    "log.setLevel(logging.DEBUG)\n",
    "format = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "#ch = logging.StreamHandler(sys.stdout)\n",
    "#ch.setFormatter(format)\n",
    "#log.addHandler(ch)\n",
    "\n",
    "#fh = logging.handlers.RotatingFileHandler(log_path+log_filename, maxBytes=(1048576*5), backupCount=7)\n",
    "fh = logging.FileHandler(log_path+log_filename, mode=\"w\")\n",
    "fh.setFormatter(format)\n",
    "\n",
    "log.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### VERSION on IS69\n",
    "if (model_version == \"s2v\"):\n",
    "    model_file = \"/opt3/home/pratima/thesis_final/models/s2v.model.bin\"\n",
    "    vocab_file = \"/opt3/home/lofi/word2vec_models/s2v.vocab\"\n",
    "    delimeter = \"|\"\n",
    "elif (model_version == \"aida\"):\n",
    "    model_file = \"/opt3/home/pratima/thesis_final/models/aida.model.bin\"\n",
    "    vocab_file = \"/opt3/home/lofi/word2vec_models/aida.vocab\"\n",
    "    delimeter = \":\"\n",
    "logging.debug(\"version: \"+model_version)\n",
    "if (gold_set == \"AGS\"):\n",
    "    golddata_file = \"/opt3/home/lofi/github/SimilarityAndAnalogy/analogy/testData/AGS/AGS-V02.txt\"\n",
    "else:\n",
    "    golddata_file = \"/opt3/home/lofi/github/SimilarityAndAnalogy/analogy/testData/SAT/crowdruns/SAT_AGS_format.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LOCAL VERSION\n",
    "\n",
    "#model_file = \"D:/data/analogy/pratima_w2v_models/aida.model.bin\"\n",
    "#model_file = \"D:/data/analogy/pratima_w2v_models/s2v.model.bin\"\n",
    "#vocab_file = \"D:/data/analogy/pratima_w2v_models/aida.vocab\"\n",
    "#golddata_file = \"../testData/AGS/AGS-V02.txt\"\n",
    "#output_file = \"./result/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### LOAD GOLD DATA\n",
    "\n",
    "def loadGoldData_AGS(dataset):\n",
    "    with open(dataset, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        simGold = []\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            line = lines[i].strip()\n",
    "            i += 1\n",
    "            if line.startswith(\":\"):\n",
    "                continue\n",
    "            if line.startswith(\"\\n\"):\n",
    "                i += 1\n",
    "                continue\n",
    "            splits = line.split(\" \")\n",
    "            correctedsplits = [ ]\n",
    "            correctedsplits.append(splits[0])\n",
    "            correctedsplits.append(splits[1])\n",
    "            correctedsplits.append(splits[2])\n",
    "            correctedsplits.append(splits[3])\n",
    "            correctedsplits.append(splits[4])\n",
    "            correctedsplits.append(splits[5])\n",
    "            correctedsplits.append(splits[6])\n",
    "            correctedsplits.append(splits[7])\n",
    "            correctedsplits.append(splits[8])\n",
    "            simGold.append(correctedsplits)\n",
    "            #print(correctedsplits)\n",
    "        return simGold\n",
    "\n",
    "\n",
    "analogydataset = loadGoldData_AGS(golddata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load Training Model. Note: s2v needs | delimeter, \n",
    "model=w2vAida.Word2Vec.load_word2vec_format(fname=model_file, binary=True, fvocab=vocab_file, delimeter=delimeter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## run word statistics for the current model\n",
    "full_words={}\n",
    "for challange in analogydataset:\n",
    "    for i in range(0, 4):\n",
    "        if not challange[i] in full_words:\n",
    "            full_words[challange[i]]=[]\n",
    "##\n",
    " # iterate over the whole vocabulary....\n",
    "for key,value in model.vocab.items():\n",
    "    # split the multi-prototype from the vocabulary into main word part, and prototype part\n",
    "    freq = value.count\n",
    "    split_key = key.split(delimeter)\n",
    "    main_keyword = split_key[0]\n",
    "    # iterate over the provided words, and check if it matches any token\n",
    "    for word in full_words:\n",
    "        # if we have indeed a match...\n",
    "        if (word == main_keyword):\n",
    "            # we keep a dictionary of statistics for each word, and add new prototypes to it when found\n",
    "            full_words[main_keyword].append([key, freq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5ce0b8671b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## get rid of unwanted vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprototypes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>>\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_words' is not defined"
     ]
    }
   ],
   "source": [
    "## get rid of unwanted vectors\n",
    "all_words=full_words\n",
    "for word, prototypes in all_words.items():\n",
    "    if verbose:\n",
    "        print(\">>>\"+word)\n",
    "    max_prototype=max(prototypes,key=operator.itemgetter(1))\n",
    "    for prototype in prototypes:\n",
    "        if verbose:\n",
    "            print(prototype)\n",
    "        if (prototype[1]<0.2*max_prototype[1]):\n",
    "            prototypes.remove(prototype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# just a test \n",
    "if (model_version==\"s2v\"):\n",
    "    print(model.n_similarity(['egg|noun', 'chick|noun'], ['larva|noun', 'insect|noun']))\n",
    "print(model.n_similarity_new(['egg','chick'],['larva','insect'], all_words=all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_columns=('a1','a2','b1','b2','ags_rating','model_rating','difficulty')\n",
    "raw_result = pd.DataFrame(columns=r_columns)\n",
    "result_file_name=log_path+model_version+\"_\"+(\"NoMinority\" if exclude_minority_vectores else \"Minority\")+\".result.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### RANKING EXPERIMENT\n",
    "if run_ranking_experiment:\n",
    "\n",
    "    \n",
    "    duplicatecount=0\n",
    "    count=0\n",
    "    countlines=0\n",
    "    previouscheckvalue=0\n",
    "    total=0\n",
    "    nextval = 0\n",
    "\n",
    "    for value in analogydataset:\n",
    "        #if(value[6]==word):\n",
    "        r_similarity = model.n_similarity_new([value[0], value[1]],[value[2],value[3]], all_words=all_words)\n",
    "        print(\"{}:{} :: {}:{}  >> {}    reference rating {}\".format(value[0], value[1], \n",
    "                                                                    value[2], value[3], r_similarity, value[4]))\n",
    "\n",
    "        countlines+=1\n",
    "        originalRating=value[4]\n",
    "        originalcheckvalue=value[0]\n",
    "       \n",
    "        row = pd.DataFrame([[value[0],value[1],value[2],value[3],value[4],r_similarity, value[8]]],columns=r_columns)\n",
    "        raw_result=raw_result.append(row)\n",
    "    raw_result.to_csv(result_file_name, encoding='utf-8')\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_result['ags_rating'] = raw_result['ags_rating'].apply(pd.to_numeric)\n",
    "grouped = raw_result.groupby((\"a1\", \"a2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define thresholds for definitly corretc, definitly incorrect, and neutral\n",
    "correct_threshold = 4\n",
    "incorrect_threshold = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six import string_types\n",
    "from numpy import ndarray\n",
    "\n",
    "def n_similarity_version2(model, all_words, one, two):\n",
    "\n",
    "    model.init_sims()\n",
    "\n",
    "    if isinstance(one, string_types) and not two:\n",
    "        # allow calls like most_similar('dog'), as a shorthand for most_similar(['dog'])\n",
    "        one = [one]\n",
    "\n",
    "    # add weights for each word, if not already present; default to 1.0 for positive and -1.0 for negative words\n",
    "    one = [(word, 1.0) if isinstance(word, string_types + (ndarray,))\n",
    "                            else word for word in one]\n",
    "    two = [(word, -1.0) if isinstance(word, string_types + (ndarray,))\n",
    "                             else word for word in two]\n",
    "\n",
    "    p = [(word, 1.0) if isinstance(word, string_types)\n",
    "                            else word for word in one]\n",
    "    n = [(word, -1.0) if isinstance(word, string_types)\n",
    "                             else word for word in two]\n",
    "\n",
    "    p1 = p[:len(p)//2]\n",
    "    p2 = p[len(p)//2:]\n",
    "    sp1 = ', '.join('{}'.format(*el) for el in p1)\n",
    "    sp2 = ', '.join('{}'.format(*el) for el in p2)\n",
    "    n1 = n[:len(n)//2]\n",
    "    n2 = n[len(n)//2:]\n",
    "    sn1 = ', '.join('{}'.format(*el) for el in n1)\n",
    "    sn2 = ', '.join('{}'.format(*el) for el in n2)\n",
    "\n",
    "    wone, wtwo, wthree, wfour= [], [], [], []\n",
    "\n",
    "\n",
    "    all_input = []\n",
    "    all_counts = {}\n",
    "\n",
    "    \n",
    "    all_counts=all_words\n",
    "    #print(\"Use given all words\")\n",
    "    for word, weight in one + two:\n",
    "        for prototype in all_counts[word]:    \n",
    "            all_input.append(prototype[0])\n",
    "\n",
    "\n",
    "    ## sort word back into the respective input buckets (yes, this is unnecesarily convoluted)\n",
    "    for f in all_input:\n",
    "        if sp1 in f:\n",
    "            wone.append(f)\n",
    "        elif sp2 in f:\n",
    "            wtwo.append(f)\n",
    "        elif sn1 in f:\n",
    "            wthree.append(f)\n",
    "        elif sn2 in f:\n",
    "            wfour.append(f)\n",
    "\n",
    "    if not wone or not wtwo or not wthree or not wfour:\n",
    "        return 0.0\n",
    "\n",
    "    intermediate=[]\n",
    "    # iterate over the crossproduct of all variants of word one and all variants of word two\n",
    "    for x1, y1, x2, y2 in [(x1,y1, x2, y2) for x1 in wone for y1 in wtwo for x2 in wthree for y2 in wfour]:\n",
    "        similarity = Word2Vec.n_similarity(model,[x1,y1],[x2,y2])\n",
    "        words = [x, y1, x2, y2]\n",
    "        l.append([similary, words])\n",
    "        # store a tuple (similarity, (w1_variant, w2_variant))\n",
    "        print(similarity+\" \"+words)\n",
    "    m = max(intermediate,key=itemgetter(0))   \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(n_similarity_version2(model=model,one=['kernel','nut'],two=['thorn','stem'], all_words=all_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### more complex statistics: correct >> incorrect\n",
    "\n",
    "### create result file\n",
    "result_columns=('name','model','difficulty')\n",
    "result = pd.DataFrame(columns=result_columns)\n",
    "result_file_name=log_path+model_version+\"_\"+(\"NoMinority\" if exclude_minority_vectores else \"Minority\")+\".result.final.csv\"\n",
    "\n",
    "# is highest correct?\n",
    "count = 0\n",
    "correct = 0\n",
    "for name, group in grouped:\n",
    "    #print(group)\n",
    "    ## select all rows which have a the maximum value for model rating\n",
    "    correct_in_ags= group[group[\"ags_rating\"] >= correct_threshold]\n",
    "    incorrect_in_ags= group[group[\"ags_rating\"] <= incorrect_threshold]\n",
    "\n",
    "    violating_rows=pd.DataFrame(columns=r_columns)\n",
    "    \n",
    "    is_correct = True\n",
    "    # compare all correct rows to all incorrect rows.\n",
    "    for i1, c_row in correct_in_ags.iterrows():\n",
    "        for i2, i_row in incorrect_in_ags.iterrows(): \n",
    "            # if an incorrect row has a better rating than a correct row, it is broken\n",
    "            if i_row[\"model_rating\"]>=c_row[\"model_rating\"]:\n",
    "                violating_rows=violating_rows.append([i_row, c_row])\n",
    "                is_correct = False\n",
    "            else:\n",
    "                pass\n",
    "        ## debug errors to console\n",
    "        if not is_correct:\n",
    "            print(violating_rows.to_string(columns=r_columns))\n",
    "            \n",
    "    count+=1\n",
    "    if (is_correct):\n",
    "        correct+=1\n",
    "    difficulty = group.iloc[0][\"difficulty\"]\n",
    "    print(difficulty)\n",
    "    resultrow = pd.DataFrame([[str(name).replace(\",\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\"), \n",
    "                               1 if is_correct else 0, difficulty]],columns=result_columns)\n",
    "    result=result.append(resultrow)\n",
    "\n",
    "result.model=result.model.astype(int)\n",
    "overal_correctness = float(correct)/count\n",
    "print(overal_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "difficulty_labels=(\"advanced\", \"hard\", \"medium\", \"easy\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "##setup styles\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "ax = sns.barplot(data=result, y=\"model\", x=\"difficulty\", ci=None, palette=\"deep\", order=difficulty_labels)\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel(\"sucessfully solved challanges [fraction]\")\n",
    "ax.set_xticklabels(labels=ax.get_xticklabels(), rotation=30)\n",
    "## add persentage axis\n",
    "\n",
    "for p in ax.patches:\n",
    "    x=p.get_bbox().get_points()[:,0]\n",
    "    y=p.get_bbox().get_points()[1,1]\n",
    "    ax.annotate('{:1.1f}%'.format(y*100), (x.mean(), y), \n",
    "            ha='center', va='bottom')\n",
    "\n",
    "\n",
    "##\n",
    "plt.title(\"Performance of \"+model_version+\" on \"+gold_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analogydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
